# ECS Auto Scaling 設定ガイド

## 概要

このドキュメントでは、NeuraKnotプロジェクトにおけるECS Auto Scalingの設定と運用について説明します。

## 設定概要

### Auto Scaling の目的

1. **コスト最適化**: トラフィックが少ない時は最小構成で運用し、不要なコストを削減
2. **可用性向上**: 負荷増加時に自動でスケールアウトし、サービスの安定性を確保
3. **運用負荷軽減**: 手動でのスケール操作が不要に

### 設定値

#### Backend Go サービス

```hcl
# タスク数の範囲
最小: 1タスク
最大: 5タスク

# スケーリングトリガー
CPU使用率: 70%
メモリ使用率: 80%

# クールダウン期間
スケールアウト: 60秒
スケールイン: 300秒（5分）
```

#### Backend Python サービス

```hcl
# タスク数の範囲
最小: 1タスク
最大: 3タスク

# スケーリングトリガー
CPU使用率: 70%
メモリ使用率: 80%

# クールダウン期間
スケールアウト: 60秒
スケールイン: 300秒（5分）
```

## スケーリング動作

### ターゲット追跡スケーリングの仕組み

Auto Scalingは、指定されたメトリクスの目標値を維持するように自動的にタスク数を調整します。

#### スケールアウト（タスク増加）の例

```
状況: CPU使用率が70%を超えた

1. 現在: 1タスク、CPU使用率 85%
2. Auto Scalingが検知（約1分）
3. 新しいタスクを起動（約30-60秒）
4. 結果: 2タスク、CPU使用率 42.5%（85% / 2）
```

#### スケールイン（タスク減少）の例

```
状況: CPU使用率が70%を大きく下回った

1. 現在: 3タスク、CPU使用率 30%
2. 5分間継続して低い使用率を確認
3. タスクを1つ削除
4. 結果: 2タスク、CPU使用率 45%（30% × 3 / 2）
```

### クールダウン期間の意味

**スケールアウト: 60秒**
- 新しいタスクを追加した後、次のスケールアウトまで最低60秒待機
- 理由: タスクの起動に時間がかかるため、急激なスケールアップを防ぐ

**スケールイン: 300秒**
- タスクを削除した後、次のスケールインまで最低5分待機
- 理由: 一時的な負荷減少でタスクを削減しすぎないよう、より慎重に動作

## コスト試算

### Fargate料金（東京リージョン）

- **vCPU**: $0.04656 / vCPU / 時間
- **メモリ**: $0.00511 / GB / 時間

### 各サービスの時間単価

#### Backend Go（0.25 vCPU, 0.5 GB）
```
時間単価 = (0.25 × $0.04656) + (0.5 × $0.00511)
         = $0.01164 + $0.002555
         = $0.014195 / タスク / 時間
```

#### Backend Python（0.5 vCPU, 1 GB）
```
時間単価 = (0.5 × $0.04656) + (1 × $0.00511)
         = $0.02328 + $0.00511
         = $0.02839 / タスク / 時間
```

### 月額コスト比較

#### 従来の固定構成
```
Backend Go:     2タスク × $0.014195 × 24時間 × 30日 = $20.52
Backend Python: 1タスク × $0.02839  × 24時間 × 30日 = $20.48
───────────────────────────────────────────────────────
合計: $40.96/月
```

#### Auto Scaling導入後（最小構成）
```
Backend Go:     1タスク × $0.014195 × 24時間 × 30日 = $10.26
Backend Python: 1タスク × $0.02839  × 24時間 × 30日 = $20.48
───────────────────────────────────────────────────────
基本コスト: $30.74/月（25%削減）
```

#### 実際の運用コスト見積もり

**シナリオ1: 軽負荷アプリケーション**
- 平常時（20時間/日）: 最小構成（1+1タスク）
- ピーク時（4時間/日）: スケールアウト（2+2タスク）

```
Backend Go:
  平常時: 1タスク × $0.014195 × 20時間 × 30日 = $8.52
  ピーク時: 2タスク × $0.014195 × 4時間 × 30日  = $3.41
  小計: $11.93

Backend Python:
  平常時: 1タスク × $0.02839 × 20時間 × 30日 = $17.03
  ピーク時: 2タスク × $0.02839 × 4時間 × 30日  = $6.81
  小計: $23.84
  
合計: $35.77/月（従来比13%削減）
```

**シナリオ2: 中負荷アプリケーション**
- 平常時（16時間/日）: 最小構成（1+1タスク）
- 中負荷（6時間/日）: 中規模（3+2タスク）
- 高負荷（2時間/日）: 最大規模（5+3タスク）

```
Backend Go:
  平常時: 1タスク × $0.014195 × 16時間 × 30日 = $6.81
  中負荷: 3タスク × $0.014195 × 6時間 × 30日  = $7.67
  高負荷: 5タスク × $0.014195 × 2時間 × 30日  = $4.26
  小計: $18.74

Backend Python:
  平常時: 1タスク × $0.02839 × 16時間 × 30日 = $13.63
  中負荷: 2タスク × $0.02839 × 6時間 × 30日  = $10.22
  高負荷: 3タスク × $0.02839 × 2時間 × 30日  = $5.11
  小計: $28.96
  
合計: $47.70/月（従来比16%増加）
```

### コスト最適化のポイント

1. **スケーリング閾値の調整**
   - CPU使用率を70%→80%に上げると、スケールアウトの頻度が減りコスト削減
   - ただし、レスポンスタイムが悪化する可能性

2. **最大タスク数の制限**
   - 予期しないコスト増加を防ぐため、最大値を適切に設定
   - Backend Go: 5タスク（最大$51/月）
   - Backend Python: 3タスク（最大$61/月）

3. **スケールインのクールダウン時間**
   - より長く設定（例: 10分）すると、頻繁なスケール操作を防ぎ安定性向上
   - ただし、コスト削減の速度は遅くなる

## 監視とアラート

### CloudWatch メトリクス

Auto Scalingの動作を監視するための主要メトリクス：

```bash
# CPU使用率
ECSServiceAverageCPUUtilization

# メモリ使用率
ECSServiceAverageMemoryUtilization

# 現在のタスク数
RunningTaskCount

# スケーリングアクティビティ
AWS/ApplicationAutoScaling
```

### 推奨アラート設定

```hcl
# 最大タスク数に到達したアラート
アラート名: ECS-Backend-Go-MaxCapacity
条件: タスク数 >= 5 for 5分
重要度: High
アクション: 通知 + ログ記録

# CPU使用率継続高負荷アラート
アラート名: ECS-Backend-Go-HighCPU
条件: CPU使用率 >= 85% for 10分
重要度: Medium
アクション: 通知

# スケーリングアクティビティ失敗
アラート名: ECS-AutoScaling-Failed
条件: スケーリングエラー発生
重要度: High
アクション: 即時通知
```

## Terraform 適用手順

### 1. 変更内容の確認

```bash
cd terraform/environments/prod
terraform plan
```

### 2. Auto Scaling 有効化

```bash
# デフォルトで有効化されています
# 無効化する場合は以下を prod.tfvars に追加:
# enable_autoscaling = false

terraform apply
```

### 3. 適用確認

```bash
# Auto Scaling ターゲットの確認
aws application-autoscaling describe-scalable-targets \
  --service-namespace ecs \
  --resource-ids service/neuraKnot-prod-cluster/neuraKnot-prod-backend-go

# スケーリングポリシーの確認
aws application-autoscaling describe-scaling-policies \
  --service-namespace ecs \
  --resource-id service/neuraKnot-prod-cluster/neuraKnot-prod-backend-go
```

## カスタマイズ方法

### スケーリング閾値の変更

`terraform/environments/prod/terraform.tfvars` に追加:

```hcl
# CPU使用率の目標値を変更（デフォルト: 70%）
backend_go_cpu_target_value = 80

# メモリ使用率の目標値を変更（デフォルト: 80%）
backend_go_memory_target_value = 85
```

### タスク数範囲の変更

```hcl
# Backend Go の最大タスク数を増やす（デフォルト: 5）
backend_go_autoscaling_max_capacity = 10

# Backend Python の最小タスク数を増やす（デフォルト: 1）
backend_python_autoscaling_min_capacity = 2
```

### Auto Scaling の無効化

```hcl
# Auto Scaling を無効化（固定タスク数で運用）
enable_autoscaling = false
```

## ベストプラクティス

### 1. 段階的な導入

```
ステップ1: dev環境で動作確認
  → 最小1タスク、最大3タスクで試験運用

ステップ2: 負荷テストの実施
  → スケーリング動作と閾値の妥当性を確認

ステップ3: prod環境への適用
  → ピークタイムを避けて適用
  → 監視を強化して数日間観察
```

### 2. スケーリングイベントのログ記録

```bash
# CloudWatch Logs Insights クエリ例
fields @timestamp, detail.statusMessage, detail.desiredCount
| filter detail.resourceId like /backend-go/
| sort @timestamp desc
| limit 100
```

### 3. 定期的な見直し

- **月次**: コスト分析とスケーリング頻度の確認
- **四半期**: 閾値とタスク数上限の見直し
- **年次**: アーキテクチャ全体の最適化検討

## トラブルシューティング

### スケールアウトしない

**原因1**: 最大タスク数に到達している
```bash
# 現在のタスク数を確認
aws ecs describe-services \
  --cluster neuraKnot-prod-cluster \
  --services neuraKnot-prod-backend-go \
  --query 'services[0].desiredCount'
```

**原因2**: IAM権限不足
```bash
# Auto Scaling のサービスリンクロールを確認
aws iam get-role --role-name AWSServiceRoleForApplicationAutoScaling_ECSService
```

### スケールインが遅い

- クールダウン期間（デフォルト: 5分）を短縮
- ただし、頻繁なスケール操作によるコスト増加に注意

### 頻繁にスケールする（フラッピング）

- CPU/メモリの目標値を調整（70% → 75%など）
- スケールインのクールダウン時間を延長（5分 → 10分）

## まとめ

### メリット

✅ **コスト削減**: 平常時25-50%のコスト削減
✅ **可用性向上**: 負荷増加時の自動対応
✅ **運用効率化**: 手動スケール操作が不要
✅ **柔軟性**: トラフィックパターンに自動追従

### 注意点

⚠️ **初期設定**: 適切な閾値の設定が重要
⚠️ **監視**: スケーリング動作の継続的な監視が必要
⚠️ **コスト**: 高負荷時は従来より高額になる可能性
⚠️ **起動時間**: タスク起動に30-60秒かかることを考慮

### 次のステップ

1. Terraform apply でAuto Scalingを有効化
2. CloudWatch ダッシュボードでメトリクスを監視
3. 1-2週間の運用データを元に閾値を最適化
4. 必要に応じてカスタムメトリクスの追加を検討


