"""
SSEã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
LangChain AsyncCallbackHandlerã‚’ä½¿ç”¨ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¤ãƒ™ãƒ³ãƒˆé…ä¿¡
"""
from langchain_core.callbacks import AsyncCallbackHandler
from langchain_core.outputs import LLMResult
from typing import Any, Dict, List
import asyncio
import time
import logging

logger = logging.getLogger(__name__)


class SSEStreamingCallback(AsyncCallbackHandler):
    """SSEã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©"""
    
    def __init__(self):
        super().__init__()
        self.queue = asyncio.Queue()
        self.tool_start_times = {}
        self.tool_insert_positions = {}  # ãƒ„ãƒ¼ãƒ«ã”ã¨ã®æŒ¿å…¥ä½ç½®ã‚’è¨˜éŒ²
        # ãƒˆãƒ¼ã‚¯ãƒ³è“„ç©ç”¨
        self.accumulated_tokens = []
        self.tool_calls = []
        self.token_usage = {"prompt": 0, "completion": 0, "total": 0}
        self.start_time = time.time()
    
    async def on_llm_new_token(self, token: str, **kwargs: Any) -> None:
        """
        æ–°ã—ã„ãƒˆãƒ¼ã‚¯ãƒ³ãŒç”Ÿæˆã•ã‚ŒãŸæ™‚

        Args:
            token: ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³
        """
        logger.info(f"Token received: {repr(token)}")
        self.accumulated_tokens.append(token)
        await self.queue.put({
            "type": "token",
            "content": token
        })
    
    async def on_tool_start(
        self,
        serialized: Dict[str, Any],
        input_str: str,
        **kwargs: Any
    ) -> None:
        """
        ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œé–‹å§‹æ™‚
        
        Args:
            serialized: ã‚·ãƒªã‚¢ãƒ«åŒ–ã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«æƒ…å ±
            input_str: ãƒ„ãƒ¼ãƒ«å…¥åŠ›
        """
        tool_name = serialized.get("name", "Unknown")
        self.tool_start_times[tool_name] = time.time()
        
        # ç¾åœ¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½ç½®ã‚’è¨˜éŒ²ï¼ˆUIè¡¨ç¤ºç”¨ï¼‰
        insert_position = len("".join(self.accumulated_tokens))
        self.tool_insert_positions[tool_name] = insert_position
        
        logger.info(f"ğŸ”§ on_tool_start called! Tool: {tool_name}, Input: {input_str}, Position: {insert_position}")
        
        event = {
            "type": "tool_start",
            "tool_id": tool_name,
            "tool_name": tool_name,
            "input": input_str,
            "insert_position": insert_position
        }
        
        await self.queue.put(event)
        logger.info(f"âœ… Tool start event queued: {event}")
    
    async def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:
        """
        LLMå®Œäº†æ™‚ - ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’å–å¾—
        
        Args:
            response: LLMã®å¿œç­”çµæœ
        """
        # stream_usage=Trueã®å ´åˆã€usage_metadataã«å«ã¾ã‚Œã‚‹
        if hasattr(response, 'generations') and response.generations:
            for generation_list in response.generations:
                for generation in generation_list:
                    if hasattr(generation, 'message') and hasattr(generation.message, 'usage_metadata'):
                        usage_meta = generation.message.usage_metadata
                        
                        if usage_meta:
                            # usage_metadataã¯è¾æ›¸å‹
                            self.token_usage = {
                                "prompt": usage_meta.get('input_tokens', 0),
                                "completion": usage_meta.get('output_tokens', 0),
                                "total": usage_meta.get('total_tokens', 0)
                            }
                            logger.info(f"âœ… Token usage from usage_metadata: {self.token_usage}")
                            return
        
        # ãƒ¬ã‚¬ã‚·ãƒ¼ãªæ–¹æ³•ï¼ˆllm_outputï¼‰ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ç¢ºèª
        if response.llm_output and "token_usage" in response.llm_output:
            usage = response.llm_output["token_usage"]
            self.token_usage = {
                "prompt": usage.get("prompt_tokens", 0),
                "completion": usage.get("completion_tokens", 0),
                "total": usage.get("total_tokens", 0)
            }
            logger.info(f"âœ… Token usage from llm_output: {self.token_usage}")
        else:
            logger.warning(f"âš ï¸ No token_usage found in llm_output or usage_metadata")
    
    async def on_tool_end(self, output: str, **kwargs: Any) -> None:
        """
        ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµ‚äº†æ™‚
        
        Args:
            output: ãƒ„ãƒ¼ãƒ«å‡ºåŠ›
        """
        tool_name = kwargs.get("name", "Unknown")
        
        # outputã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        output_str = str(output) if output else ""
        
        logger.info(f"âœ… on_tool_end called! Tool: {tool_name}, Output type: {type(output)}, Output: {output_str[:200]}")
        
        # å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆç®—
        execution_time_ms = 0
        if tool_name in self.tool_start_times:
            execution_time_ms = int((time.time() - self.tool_start_times[tool_name]) * 1000)
            del self.tool_start_times[tool_name]
        
        # æŒ¿å…¥ä½ç½®ã‚’å–å¾—
        insert_position = self.tool_insert_positions.get(tool_name, 0)
        if tool_name in self.tool_insert_positions:
            del self.tool_insert_positions[tool_name]
        
        # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—æƒ…å ±ã‚’è“„ç©
        tool_call_info = {
            "tool_id": tool_name,
            "tool_name": tool_name,
            "status": "completed",
            "input": kwargs.get("input", {}),
            "output": output_str[:500],
            "error": None,
            "execution_time_ms": execution_time_ms,
            "insert_position": insert_position
        }
        self.tool_calls.append(tool_call_info)
        
        event = {
            "type": "tool_end",
            "tool_id": tool_name,
            "status": "completed",
            "output": output_str[:500],  # æœ€åˆã®500æ–‡å­—
            "error": None,
            "execution_time_ms": execution_time_ms
        }
        
        await self.queue.put(event)
        logger.info(f"âœ… Tool end event queued with output length: {len(output_str)}")
    
    async def on_tool_error(self, error: Exception, **kwargs: Any) -> None:
        """
        ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼æ™‚
        
        Args:
            error: ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼
        """
        tool_name = kwargs.get("name", "Unknown")
        
        # å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆç®—
        execution_time_ms = 0
        if tool_name in self.tool_start_times:
            execution_time_ms = int((time.time() - self.tool_start_times[tool_name]) * 1000)
            del self.tool_start_times[tool_name]
        
        # æŒ¿å…¥ä½ç½®ã‚’å–å¾—
        insert_position = self.tool_insert_positions.get(tool_name, 0)
        if tool_name in self.tool_insert_positions:
            del self.tool_insert_positions[tool_name]
        
        # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—æƒ…å ±ã‚’è“„ç©
        tool_call_info = {
            "tool_id": tool_name,
            "tool_name": tool_name,
            "status": "failed",
            "input": kwargs.get("input", {}),
            "output": "",
            "error": str(error),
            "execution_time_ms": execution_time_ms,
            "insert_position": insert_position
        }
        self.tool_calls.append(tool_call_info)
        
        await self.queue.put({
            "type": "tool_end",
            "tool_id": tool_name,
            "status": "failed",
            "output": "",
            "error": str(error),
            "execution_time_ms": execution_time_ms
        })
        
        logger.error(f"Tool error: {tool_name} - {str(error)}")
    
    async def on_agent_finish(self, finish: Any, **kwargs: Any) -> None:
        """
        ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Œäº†æ™‚
        
        Args:
            finish: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Œäº†æƒ…å ±
        
        Note:
            doneã‚¤ãƒ™ãƒ³ãƒˆã¯chat.pyã®run_agenté–¢æ•°å†…ã§å®Œå…¨ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨å…±ã«é€ä¿¡ã•ã‚Œã‚‹ãŸã‚ã€
            ã“ã“ã§ã¯ä½•ã‚‚ã—ãªã„ã€‚
        """
        logger.info("Agent finished - done event will be sent by run_agent()")
    
    async def on_llm_error(self, error: Exception, **kwargs: Any) -> None:
        """
        LLMã‚¨ãƒ©ãƒ¼æ™‚
        
        Args:
            error: ç™ºç”Ÿã—ãŸã‚¨ãƒ©ãƒ¼
        """
        await self.queue.put({
            "type": "error",
            "code": "LLM_API_ERROR",
            "message": str(error)
        })
        
        logger.error(f"LLM error: {str(error)}")
    
    async def get_events(self):
        """
        ã‚¤ãƒ™ãƒ³ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ å–å¾—
        
        Yields:
            ã‚¤ãƒ™ãƒ³ãƒˆè¾æ›¸
        """
        while True:
            try:
                event = await asyncio.wait_for(
                    self.queue.get(),
                    timeout=60.0
                )
                yield event
                if event.get("type") == "done" or event.get("type") == "error":
                    break
            except asyncio.TimeoutError:
                logger.warning("SSE stream timeout")
                break

